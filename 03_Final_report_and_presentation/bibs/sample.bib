
@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}
@inproceedings{learnedTetheredPerchingFabian,
title = "Learning Tethered Perching for Aerial Robots",
abstract = "Aerial robots have a wide range of applications, such as collecting data in hard-to-reach areas. This requires the longest possible operation time. However, because currently available commercial batteries have limited specific energy of roughly 300 W h kg-1, a drone's flight time is a bottleneck for sustainable long-term data collection. Inspired by birds in nature, a possible approach to tackle this challenge is to perch drones on trees, and environmental or man-made structures, to save energy whilst in operation. In this paper, we propose an algorithm to automatically generate trajectories for a drone to perch on a tree branch, using the proposed tethered perching mechanism with a pendulum-like structure. This enables a drone to perform an energy-optimised, controlled 180° flip to safely disarm upside down. To fine-tune a set of reachable trajectories, a soft actor critic-based reinforcement algorithm is used. Our experimental results show the feasibility of the set of trajectories with successful perching. Our findings demonstrate that the proposed approach enables energy-efficient landing for long-term data collection tasks.",
author = "Fabian Hauf and Kocer, {Basaran Bahadir} and Alan Slatter and Nguyen, {Hai Nguyen} and Oscar Pang and Ronald Clark and Edward Johns and Mirko Kovac",
note = "Funding Information: We also thank former Aerial Robotics Lab members who have explored the work at various levels, particularly Bojia Mao and Kobi Kelemen. This work was partially supported by funding from EPSRC (award no. EP/N018494/1, EP/R026173/1, EP/R009953/1, EP/S031464/1, EP/W001136/1), NERC (award no. NE/R012229/1) and the EU H2020 AeroTwin project (grant ID 810321). Mirko Kovac is supported by the Royal Society Wolfson fellowship (RSWF/R1/18003). For the purpose of open access, the author(s) has applied a Creative Commons Attribution (CC BY) license to any Accepted Manuscript version arising. Publisher Copyright: {\textcopyright} 2023 IEEE.; 2023 IEEE International Conference on Robotics and Automation, ICRA 2023 ; Conference date: 29-05-2023 Through 02-06-2023",
year = "2023",
doi = "10.1109/ICRA48891.2023.10161135",
language = "English",
series = "Proceedings - IEEE International Conference on Robotics and Automation",
publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
pages = "1298--1304",
booktitle = "Proceedings - ICRA 2023",
address = "United States",
}
@incollection{abbeelRLAerobaticFlight,
    author = {Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng, Andrew Y.},
    isbn = {9780262256919},
    title = "{An Application of Reinforcement Learning to Aerobatic Helicopter Flight}",
    booktitle = "{Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference}",
    publisher = {The MIT Press},
    year = {2007},
    month = {09},
    doi = {10.7551/mitpress/7503.003.0006},
    url = {https://doi.org/10.7551/mitpress/7503.003.0006},
    eprint = {https://direct.mit.edu/book/chapter-pdf/2139612/9780262256919\_caa.pdf},
}
@misc{deepQLearningFromDemo,
      title={Deep Q-learning from Demonstrations}, 
      author={Todd Hester and Matej Vecerik and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Dan Horgan and John Quan and Andrew Sendonaris and Gabriel Dulac-Arnold and Ian Osband and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
      year={2017},
      eprint={1704.03732},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@article{SACfDMaplessNavigation,
abstract = {This paper is concerned with the problems of mapless navigation for unmanned aerial vehicles in the scenarios with limited sensor accuracy and computing capability. A novel learning-based algorithm called soft actor-critic from demonstrations (SACfD) is proposed, integrating reinforcement learning with imitation learning. Specifically, the maximum entropy reinforcement learning framework is introduced to enhance the exploration capability of the algorithm, upon which the paper explores a way to sufficiently leverage demonstration data to significantly accelerate the convergence rate while improving policy performance reliably. Further, the proposed algorithm enables an implementation of mapless navigation for unmanned aerial vehicles and experimental results show that it outperforms the existing algorithms.},
author = {Yang, JiaNan and Lu, ShengAo and Han, MingHao and Li, YunPeng and Ma, YuTing and Lin, ZeFeng and Li, HaoWei},
address = {Beijing},
copyright = {Science China Press 2023},
issn = {1674-7321},
journal = {Science China. Technological sciences},
keywords = {Algorithms ; Engineering ; Machine learning ; Maximum entropy ; Navigation ; Unmanned aerial vehicles},
language = {eng},
number = {5},
pages = {1263-1270},
publisher = {Science China Press},
title = {Mapless navigation for UAVs via reinforcement learning from demonstrations},
volume = {66},
year = {2023}}

@article{aerialNavReview,
author = {AlMahamid, Fadi and Grolinger, Katarina},
issn = {0952-1976},
journal = {Engineering applications of artificial intelligence},
language = {eng},
pages = {105321-},
title = {Autonomous Unmanned Aerial Vehicle navigation using Reinforcement Learning: A systematic review},
volume = {115},
year = {2022},
}

@article{droneReview,
    author = {Chan, K. W. and Nirmal, U. and Cheaw, W. G.},
    title = "{Progress on drone technology and their applications: A comprehensive review}",
    journal = {AIP Conference Proceedings},
    volume = {2030},
    number = {1},
    pages = {020308},
    year = {2018},
    month = {11},
    abstract = "{The current work is a development of an interface to control a wireless drone for home security applications. A review had been done for the categorization of drones and drones’ trend for recent years. It was found that drones were basically categorized by weight and flight range and number of drones increased by leaps and bounds from year 2003 to year 2017. The history of drones and recent-year-founded applications were being reviewed as well. A research was being done on 19 types of drones which are available in current market such as DJI Phantom 4 and GoPro Karma and their applications. To the summary of the review, drones’ technology will be advancing with the current rate of development of technology and it will be more applicable to our daily life in the future. Proposed future research pathways on drone’s technology and their applications were being done as well to understand the future trend and possible advancement for drones.}",
    issn = {0094-243X},
    doi = {10.1063/1.5066949},
    url = {https://doi.org/10.1063/1.5066949},
    eprint = {https://pubs.aip.org/aip/acp/article-pdf/doi/10.1063/1.5066949/14170335/020308\_1\_online.pdf},
}
@INPROCEEDINGS{environmentalSensing,
  author={Kocer, Basaran Bahadir and Ho, Boon and Zhu, Xuanhao and Zheng, Peter and Farinha, André and Xiao, Feng and Stephens, Brett and Wiesemüller, Fabian and Orr, Lachlan and Kovac, Mirko},
  booktitle={2021 Aerial Robotic Systems Physically Interacting with the Environment (AIRPHARO)}, 
  title={Forest Drones for Environmental Sensing and Nature Conservation}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/AIRPHARO52252.2021.9571033}}

@Article{droneBattery,
AUTHOR = {Hwang, Myeong-hwan and Cha, Hyun-Rok and Jung, Sung Yong},
TITLE = {Practical Endurance Estimation for Minimizing Energy Consumption of Multirotor Unmanned Aerial Vehicles},
JOURNAL = {Energies},
VOLUME = {11},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2221},
URL = {https://www.mdpi.com/1996-1073/11/9/2221},
ISSN = {1996-1073},
ABSTRACT = {The practically applicable endurance estimation method for multirotor unmanned aerial vehicles (UAVs) using a battery as a power source is proposed. The method considers both hovering and steady-level flights. The endurance, thrust, efficiency, and battery discharge are determined with generally available data from the manufacturer. The effects of the drag coefficient related to vehicle shape and payload weight are examined at various forward flight speeds. As the drag coefficient increases, the optimum speed at the minimum required power and the maximum endurance are reduced. However, the payload weight causes an opposite effect, and the optimal flying speed increases with an increase in the payload weight. For more practical applications for common users, the value of S &times; Cd is determined from a preliminary flight test. Given this value, the endurance is numerically estimated and validated with the measured flight time. The proposed method can successfully estimate the flight time with an average error of 2.3%. This method would be useful for designers who plan various missions and select UAVs.},
DOI = {10.3390/en11092221}
}
@article{droneSunlight,
abstract = {Sunlight energy is potentially excellent for small drones, which can often operate during daylight hours and fly high enough to avoid cloud blockade. However, the best solar cells provide limited power, compared to conventional power sources, making their use for aerial vehicles difficult to realize, especially in rotorcraft where significant lift ordinarily generated by a wing is already sacrificed for the ability to hover. In recent years, advances in materials (use of carbon‐fiber components, improvement in specific solar cells and motors) have finally brought solar rotorcraft within reach. Here, the application is explored through a concise mathematical model of solar rotorcraft based on the limits of solar power generation and motor power consumption. Multiple solar quadcopters based on this model with majority solar power are described. One of them has achieved an outdoor airtime over 3 hours, 48 times longer than it can last on just battery alone with the solar cells carried as dead weight and representing a significant prolongation of drone operation. Solar‐power fluctuations during long flight and their interaction with power requirements are experimentally characterized. The general conclusion is that solar cells have reached high enough efficiencies and can outperform batteries under the right conditions for quadcopters.
A quadcopter using on‐board solar module to harvest sunlight outdoors achieves over 3 h airtime, the longest for quadcopters without using chemical fuels and about 48 times more than using battery only. The accumulated charge generated from sunlight is 33 300 mAh, which would require a battery much heavier than the solar module and beyond the thrust capability to carry.},
author = {Lin, Ching‐Fuh and Lin, Ta‐Jung and Liao, Wei‐Sheng and Lan, Hsiang and Lin, Jiun‐Yu and Chiu, Chi‐Han and Danner, Aaron},
address = {Weinheim},
copyright = {2020 The Authors. Published by Wiley‐VCH GmbH},
issn = {2198-3844},
journal = {Advanced science},
keywords = {Aircraft ; airtime ; Alternative energy sources ; Automotive engineering ; Aviation ; chemical sciences ; Computer science ; Daylight ; Dead weight ; Drone ; Efficiency ; engineering and technology ; Fossil fuels ; general chemistry ; Motor power ; nano-technology ; nanoscience & nanotechnology ; natural sciences ; Power-to-weight ratio ; Quadcopter ; quadcopters ; Science ; solar cells ; Solar energy ; Solar power ; Sunlight ; Vehicles},
language = {eng},
number = {20},
pages = {2001497-n/a},
publisher = {John Wiley & Sons, Inc},
title = {Solar Power Can Substantially Prolong Maximum Achievable Airtime of Quadcopter Drones},
volume = {7},
year = {2020}}

@article{rlIntroSuttonBarlo,
author = {Johnson, Jeffrey D and Li, Jinghong and Chen, Zengshi},
copyright = {2000 Elsevier Science Ltd},
issn = {0925-2312},
journal = {Neurocomputing (Amsterdam)},
language = {eng},
number = {1},
pages = {205-206},
publisher = {Elsevier B.V},
title = {Reinforcement Learning: An Introduction: R.S. Sutton, A.G. Barto, MIT Press, Cambridge, MA 1998, 322 pp. ISBN 0-262-19398-1},
volume = {35},
year = {2000},
}

@article{humanLevelControlDQN,
abstract = {The theory of reinforcement learning provides a normative account (1), deeply rooted in psychological (2) and neuroscientific (3) perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems (4,5), the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms (3). While reinforcement learning agents have achieved some successes in a variety of domains (6-8), their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks (9-11) to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games (12). We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
author = {Volodymyr Mnih and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
address = {London},
copyright = {COPYRIGHT 2015 Nature Publishing Group},
issn = {0028-0836},
journal = {Nature (London)},
keywords = {Algorithms ; Artificial intelligence ; Artificial neural network ; Computer & video games ; Computer science ; General video game playing ; Methods ; Neural networks ; Physiological aspects ; Psychological aspects ; Q-learning ; Reinforcement ; Reinforcement learning ; Reinforcement learning (Machine learning) ; Sensory processing ; Set (psychology) ; Temporal difference learning},
language = {eng},
number = {7540},
pages = {529-533},
publisher = {Nature Publishing Group},
title = {Human-level control through deep reinforcement learning},
volume = {518},
year = {2015},
}

@INPROCEEDINGS{fyp12-waypoint-navigation,
  author={Eslamiat, Hossein and Li, Yilan and Wang, Ningshan and Sanyal, Amit K. and Qiu, Qinru},
  booktitle={2019 18th European Control Conference (ECC)}, 
  title={Autonomous Waypoint Planning, Optimal Trajectory Generation and Nonlinear Tracking Control for Multi-rotor UAVs}, 
  year={2019},
  volume={},
  number={},
  pages={2695-2700},
  doi={10.23919/ECC.2019.8795855}}
@inproceedings{fyp12-waypoint-nav2,
  title={Autonomous waypoints planning and trajectory generation for multi-rotor UAVs},
  author={Li, Yilan and Eslamiat, Hossein and Wang, Ningshan and Zhao, Ziyi and Sanyal, Amit K and Qiu, Qinru},
  booktitle={Proceedings of the Workshop on Design Automation for CPS and IoT},
  pages={31--40},
  year={2019}
}
@misc{fyp14-rl-imperfect-demos,
      title={Reinforcement Learning from Imperfect Demonstrations}, 
      author={Yang Gao and Huazhe Xu and Ji Lin and Fisher Yu and Sergey Levine and Trevor Darrell},
      year={2019},
      eprint={1802.05313},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@INPROCEEDINGS{fyp10-sac-Inhibitory,
  author={Choi, Minkyu and Filter, Max and Alcedo, Kevin and Walker, Thayne T. and Rosenbluth, David and Ide, Jaime S.},
  booktitle={2022 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
  title={Soft Actor-Critic with Inhibitory Networks for Retraining UAV Controllers Faster}, 
  year={2022},
  volume={},
  number={},
  pages={1561-1570},
  doi={10.1109/ICUAS54217.2022.9836052}}

@article{fyp10-initial-transfer-learning,
abstract = {Smart and agile drones are fast becoming ubiquitous at the edge of the cloud. The usage of these drones is constrained by their limited power and compute capability. In this paper, we present a Transfer Learning (TL) based approach to reduce on-board computation required to train a deep neural network for autonomous navigation via value-based Deep Reinforcement Learning for a target algorithmic performance. A library of 3D realistic meta-environments is manually designed using Unreal Gaming Engine and the network is trained end-to-end. These trained meta-weights are then used as initializers to the network in a test environment and fine-tuned for the last few fully connected layers. Variation in drone dynamics and environmental characteristics is carried out to show robustness of the approach. Using NVIDIA GPU profiler, it was shown that the energy consumption and training latency is reduced by 3.7\times and 1.8\times respectively without significant degradation in the performance in terms of average distance traveled before crash i.e. Mean Safe Flight (MSF). The approach is also tested on a real environment using DJI Tello drone and similar results were reported. The code for the approach can be found on GitHub: https://github.com/aqeelanwar/DRLwithTL.},
author = {Anwar, Aqeel and Raychowdhury, Arijit},
address = {Piscataway},
copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2020},
issn = {2169-3536},
journal = {IEEE access},
keywords = {Artificial neural networks ; Autonomous navigation ; Autonomous robots ; Constraints ; Deep learning ; deep reinforcement learning ; drone ; Drones ; Energy consumption ; Machine learning ; Reinforcement learning ; Task analysis ; Training ; transfer learning},
language = {eng},
pages = {26549-26560},
publisher = {IEEE},
title = {Autonomous Navigation via Deep Reinforcement Learning for Resource Constraint Edge Nodes Using Transfer Learning},
volume = {8},
year = {2020},
}

@INPROCEEDINGS{fyp13-noise-injection,
  author={Villanueva, Alonica and Fajardo, Arnel},
  booktitle={2019 IEEE 6th International Conference on Engineering Technologies and Applied Sciences (ICETAS)}, 
  title={Deep Reinforcement Learning with Noise Injection for UAV Path Planning}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICETAS48360.2019.9117478}}

@article{fyp16-forgetful-experience-replay,
title = {Forgetful experience replay in hierarchical reinforcement learning from expert demonstrations},
journal = {Knowledge-Based Systems},
volume = {218},
pages = {106844},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106844},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121001076},
author = {Alexey Skrynnik and Aleksey Staroverov and Ermek Aitygulov and Kirill Aksenov and Vasilii Davydov and Aleksandr I. Panov},
keywords = {Expert demonstrations, ForgER, Hierarchical reinforcement learning, Learning from demonstrations, Task-oriented augmentation, Goal-oriented reinforcement learning},
abstract = {Deep reinforcement learning (RL) shows impressive results in complex gaming and robotic environments. These results are commonly achieved at the expense of huge computational costs and require an incredible number of episodes of interactions between the agent and the environment. Hierarchical methods and expert demonstrations are among the most promising approaches to improve the sample efficiency of reinforcement learning methods. In this paper, we propose a combination of methods that allow the agent to use low-quality demonstrations in complex vision-based environments with multiple related goals. Our Forgetful Experience Replay (ForgER) algorithm effectively handles expert data errors and reduces quality losses when adapting the action space and states representation to the agent’s capabilities. The proposed goal-oriented replay buffer structure allows the agent to automatically highlight sub-goals for solving complex hierarchical tasks in demonstrations. Our method has a high degree of versatility and can be integrated into various off-policy methods. The ForgER surpasses the existing state-of-the-art RL methods using expert demonstrations in complex environments. The solution based on our algorithm beats other solutions for the famous MineRL competition and allows the agent to demonstrate the behavior at the expert level.}
}

@misc{fyp-16-prioritised-experience-replay,
      title={Prioritized Experience Replay}, 
      author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
      year={2016},
      eprint={1511.05952},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{fyp15-demo-guided-rl-with-skills,
      title={Demonstration-Guided Reinforcement Learning with Learned Skills}, 
      author={Karl Pertsch and Youngwoon Lee and Yue Wu and Joseph J. Lim},
      year={2021},
      eprint={2107.10253},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{perching-uneven-ground,
abstract = {Digital image processing serves as a multifunctional tool for measurement and positioning tasks in robotics. The present paper deals with the development of a camera-based positioning system for quadrocopters in order to automate their landing process. In this regard, a quadrocopter equipped with classical radio-control components is upgraded with applicable hardware, such as a Raspberry Pi 3B+ and a wide-angle camera. Hereupon, black-box system identifications are executed to attain the relevant plants of the attitude control performed by the flight controller. Thereby, a PID-controller for the altitude control including a back-calculation anti-windup as well as two PD-controllers for the horizontal plane are designed using a pole placement method. Effective tests of the controller gains are conducted by simulating the closed loops respectively. Since the camera functions as a position sensor, an image processing algorithm is then implemented to detect a distinctive landing symbol in real time while converting its image position into compliant feedback errors (pixel-to-physical distance-conversion). Ultimately, the developed system allows for the robust detection and successful landing on the landing spot by a position control operating at 20 hertz.},
author = {Demirhan, Malik and Premachandra, Chinthaka},
address = {Piscataway},
copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2020},
issn = {2169-3536},
journal = {IEEE access},
keywords = {Algorithms ; Altitude control ; analytical chemistry ; Anti-windup ; Artificial intelligence ; Attitude control ; Automation ; Autonomous drone ; Cameras ; chemical sciences ; Closed loops ; Computer science ; Computer vision ; control engineering ; Control theory ; Controllers ; Digital image processing ; Digital imaging ; electrical & electronic engineering ; electrical engineering, electronic engineering, information engineering ; Electrical engineering. Electronics. Nuclear engineering ; engineering and technology ; Flight control systems ; Hardware ; Image processing ; landing ; Landing aids ; natural sciences ; PID ; PID controller ; Pole placement ; Position control ; Position sensing ; Position sensor ; Positioning system ; Proportional integral derivative ; quadrocopter ; Radio control ; region of interest ; Robotics ; System identification ; TK1-9971 ; Upgrading ; wide angle camera},
language = {eng},
pages = {202111-202121},
publisher = {IEEE},
title = {Development of an Automated Camera-Based Drone Landing System},
volume = {8},
year = {2020},
}

@inproceedings{perching-water1,
abstract = {This paper presents a cost-effective multipurpose drone equipped with multiple functionalities including water floating mechanism, water sampling, onboard sensor enabled water & air quality monitoring, live video surveillance using GPS and video recording capability. The proposed system integrates a water floating mechanism on the system capable of landing & floating on water surface with high degree of stability & precision. It can collect water samples with 50 ml to 100 ml per flight from surface of water sources including pits, ponds etc with stable water current. The system is equipped with video & image surveillance mechanism on the board with GPS and video recording capability. We have equipped high quality Go-Pro 6 HD action camera on our UAV. The system is capable of sending high quality live video/image feeds directly to the base station in real time. It is also equipped with CO & AQI gas sensors to monitor air samples at multiple locations & provide live feeds on air quality index to base stations for its further analysis on quality. This paper presents a working model & results of few experiments that are carried out at initial level. The system has been tested on few parameters including sampling rate, cost effectiveness, efficiency, water & air quality index, payload, video surveillance etc. This work is a part of the research project funded by our affiliating university "A.P.J Abdul Kalam Technical University, Lucknow, U.P, India.},
author = {Agarwal, Pankaj and Singh, Mukesh Kr},
booktitle = {2019 Second International Conference on Advanced Computational and Communication Paradigms (ICACCP)},
isbn = {1538679892},
keywords = {Air quality ; Batteries ; Cameras ; Drones ; live video surveillance etc ; Monitoring ; Multipurpose drone ; Quadcopter ; Rivers ; water & air quality monitoring ; Water resources ; water sampling},
language = {eng},
pages = {1-5},
publisher = {IEEE},
title = {A multipurpose drone for water sampling \& video surveillance},
year = {2019},
}

@inproceedings{perching-water2,
abstract = {In this paper, a new capture system for UAV precision landing in a disturbed environment is proposed. Compared with the traditional visual guided landing methods, perching mechanism based methods, and tethered landing methods, the proposed system takes into account the stability during landing process and retains the high accessibility of the UAV. The proposed system consists of a winch subsystem and a magnetic catcher device. They establish an automatic tethered-UAV system for landing before the UAV touchdown. We analyzed the design principle as well as the feasibility of the magnetic catcher. An optimization problem is formulated to obtain a better layout of magnets on the catcher. The problem is relaxed based on interpolation simulation of attraction force. Experiments are conducted both in indoor and outdoor environments based on different UAV platforms respectively. The results validate that the catcher design and the capture system can achieve a successful landing in both cases.},
author = {Liu, Chongfeng and Jiang, Zixing and Xu, Ruoyu and Ji, Xiaoqiang and Zhang, Lianxin and Qian, Huihuan},
booktitle = {2022 International Conference on Robotics and Automation (ICRA)},
isbn = {9781728196817},
keywords = {Automation ; Force ; Interpolation ; Layout ; Magnetic devices ; Visualization ; Winches},
language = {eng},
pages = {1162-1168},
publisher = {IEEE},
title = {Design and Optimization of a Magnetic Catcher for UAV Landing on Disturbed Aquatic Surface Platforms},
year = {2022},
}

@inproceedings{perching-vertical-surface,
abstract = {One important issue of multirotor UAVs is their limited operational time due to their high power consumption. This issue may hinder the application of aerial robots for security purposes as their flight endurance can be exploited for just a finite amount of time, which is not necessarily sufficient in realistic surveillance scenarios. In order to achieve long endurance missions with multirotor UAVs, e.g. for crowd-surveillance, it can be beneficial to perch the UAV while it is operative to increase the operation time. This work presents an aerial manipulator that allows for reliable and reversible perching of multirotor UAVs on smooth vertical surfaces, using a lightweight mechanism based on passive vacuum-cup technology and the absorption of aerial impacts. This contributes towards enabling drones to become more flexible security systems for long endurance missions, as it allows them to position themselves passively in the environment. In this work, the design of the aerial perching mechanism is presented, as well as the perching strategy performed to achieve reliable perching. Experimental results demonstrate the relevant capabilities of the system for a drone weighing approximately 1.8 kg, including stable perching on the environment, disarming the rotors and reliable take-off.},
author = {Wopereis, H. W. and van der Molen, T. D. and Post, T. H. and Stramigioli, S. and Fumagalli, M.},
booktitle = {2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
isbn = {9781509043491},
keywords = {Force ; Manipulator dynamics ; Reliability ; Security ; Surface impedance ; Vacuum systems},
language = {eng},
pages = {154-159},
publisher = {IEEE},
title = {Mechanism for perching on smooth surfaces using aerial impacts},
year = {2016},
}

@misc{perching-magnets,
abstract = {Flying has an advantage when compared to ground based locomotion, as it simplifies the task of overcoming obstacles and allows for rapid coverage of an area while also providing a birds-eye-view of the environment. One of the key challenges that has prevented engineers from coming up with convincing aerial solutions for indoor exploration is the energetic cost of flying. This paper presents a way of mitigating the energy problem regarding aerial exploration within indoor environments. This is achieved by means of a model to estimate the endurance of a hover-capable flying robot and by using ceiling attachment as a means of preserving energy while maintaining a birds-eye-view. The proposed model for endurance estimation has been extensively tested using a custom-developed quadrotor and autonomous ceiling attachment system.},
author = {Roberts, James F and Zufferey, Jean-Christophe and Floreano, Dario},
language = {eng},
publisher = {Nice, France},
title = {Energy Management for Indoor Hovering Robots},
}

@article{perching-gripper1,
abstract = {Micro aerial vehicles (MAVs) with multiple rotors, or multicopters, have many promising applications ranging from environmental monitoring, agricultural inspection, to package delivery. These applications, however, usually face a critical problem: the flight time of MAVs is limited due to the low aerodynamic efficiency and high energy consumption. One promising solution is to make them rest on desired objects using perching, an important capability in biological flyers (e.g., birds). In this article, we present the design and experimentation of a novel perching mechanism: a low cost, 3-D-printed gripper with bistability (i.e., two stable states). The gripper has two unique characteristics. First, using bistability, it can passively switch from open to closed state using the impact between the gripper and the perching object, alleviating the requirement for precise motion control. Second, the gripper has two perching methods for different objects. For objects with a small height, it can form a closed diamond shape to encircle the objects (encircling method). For objects with a large height, the gripper's two fingers can clip on each side of the objects to utilize the friction forces for perching (clipping method). We analyze the proposed gripper design to predict the required force for opening and closing the gripper. We also predict the size of objects that will allow for successful perching for the clipping method. All the theoretical analyses are experimentally verified. Finally, we integrate the gripper onto a palm-size quadcopter to enable a mechatronic system for perching, and demonstrate successful perching with both clipping and encircling methods as well as aerial grasping. Although our bistable gripper is used with a palm-size quadcopter, the design strategy can also be applied to large-size MAVs for both energy efficient perching and aerial grasping.},
author = {Zhang, Haijie and Lerner, Elisha and Cheng, Bo and Zhao, Jianguo},
address = {New York},
copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) 2021},
issn = {1083-4435},
journal = {IEEE/ASME transactions on mechatronics},
keywords = {Aerial grasping ; Bistability ; bistable mechanism ; Clipping (computer graphics) ; Computer science ; Diamonds ; Energy consumption ; Environmental monitoring ; Experimentation ; Flight time ; Force ; Grasping ; Grippers ; IEEE transactions ; Inspection ; Mechanism (engineering) ; Mechatronics ; micro aerial vehicles (MAVs) ; Micro air vehicles (MAV) ; Motion control ; perching ; Quadcopter ; Ranging ; Shape ; Simulation ; Switches ; Three dimensional printing},
language = {eng},
number = {5},
pages = {2316-2326},
publisher = {IEEE},
title = {Compliant Bistable Grippers Enable Passive Perching for Micro Aerial Vehicles},
volume = {26},
year = {2021},
}

@inproceedings{perching-gripper2,
abstract = {Current grasping methods for aerial vehicles are slow, inaccurate and they cannot adapt to any target object. Thus, they do not allow for on-the-fly, ultra-fast grasping. In this paper, we present a passive closing, adaptive robot hand design that offers ultra-fast, aerial grasping for a wide range of everyday objects. We investigate alternative uses of structural compliance for the development of simple, adaptive robot grippers and hands and we propose an appropriate quick release mechanism that facilitates an instantaneous grasping execution. The quick release mechanism is triggered by a simple distance sensor. The proposed hand utilizes only two actuators to control multiple degrees of freedom over three fingers and it retains the superior grasping capabilities of adaptive grasping mechanisms, even under significant object pose or other environmental uncertainties. The hand achieves a grasping time of 96 ms, a maximum grasping force of 56 N and it is able to secure objects of various shapes at high speeds. The proposed hand can serve as the end-effector of grasping capable Unmanned Aerial Vehicle (UAV) platforms and it can offer perching capabilities, facilitating autonomous docking.},
author = {McLaren, Andrew and Fitzgerald, Zak and Gao, Geng and Liarokapis, Minas},
booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
isbn = {1728140048},
issn = {2153-0866},
language = {eng},
pages = {5602-5607},
publisher = {IEEE},
title = {A Passive Closing, Tendon Driven, Adaptive Robot Hand for Ultra-Fast, Aerial Grasping and Perching},
year = {2019},
}

@ARTICLE{perching-tum-bird,
  author={Broers, Krispin C. V. and Armanini, Sophie F.},
  journal={IEEE Robotics and Automation Letters}, 
  title={Design and Testing of a Bioinspired Lightweight Perching Mechanism for Flapping-Wing MAVs Using Soft Grippers}, 
  year={2022},
  volume={7},
  number={3},
  pages={7526-7533},
  doi={10.1109/LRA.2022.3184447}}

