@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}
@inproceedings{learnedTetheredPerchingFabian,
title = "Learning Tethered Perching for Aerial Robots",
abstract = "Aerial robots have a wide range of applications, such as collecting data in hard-to-reach areas. This requires the longest possible operation time. However, because currently available commercial batteries have limited specific energy of roughly 300 W h kg-1, a drone's flight time is a bottleneck for sustainable long-term data collection. Inspired by birds in nature, a possible approach to tackle this challenge is to perch drones on trees, and environmental or man-made structures, to save energy whilst in operation. In this paper, we propose an algorithm to automatically generate trajectories for a drone to perch on a tree branch, using the proposed tethered perching mechanism with a pendulum-like structure. This enables a drone to perform an energy-optimised, controlled 180Â° flip to safely disarm upside down. To fine-tune a set of reachable trajectories, a soft actor critic-based reinforcement algorithm is used. Our experimental results show the feasibility of the set of trajectories with successful perching. Our findings demonstrate that the proposed approach enables energy-efficient landing for long-term data collection tasks.",
author = "Fabian Hauf and Kocer, {Basaran Bahadir} and Alan Slatter and Nguyen, {Hai Nguyen} and Oscar Pang and Ronald Clark and Edward Johns and Mirko Kovac",
note = "Funding Information: We also thank former Aerial Robotics Lab members who have explored the work at various levels, particularly Bojia Mao and Kobi Kelemen. This work was partially supported by funding from EPSRC (award no. EP/N018494/1, EP/R026173/1, EP/R009953/1, EP/S031464/1, EP/W001136/1), NERC (award no. NE/R012229/1) and the EU H2020 AeroTwin project (grant ID 810321). Mirko Kovac is supported by the Royal Society Wolfson fellowship (RSWF/R1/18003). For the purpose of open access, the author(s) has applied a Creative Commons Attribution (CC BY) license to any Accepted Manuscript version arising. Publisher Copyright: {\textcopyright} 2023 IEEE.; 2023 IEEE International Conference on Robotics and Automation, ICRA 2023 ; Conference date: 29-05-2023 Through 02-06-2023",
year = "2023",
doi = "10.1109/ICRA48891.2023.10161135",
language = "English",
series = "Proceedings - IEEE International Conference on Robotics and Automation",
publisher = "Institute of Electrical and Electronics Engineers (IEEE)",
pages = "1298--1304",
booktitle = "Proceedings - ICRA 2023",
address = "United States",
}
@incollection{abbeelRLAerobaticFlight,
    author = {Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng, Andrew Y.},
    isbn = {9780262256919},
    title = "{An Application of Reinforcement Learning to Aerobatic Helicopter Flight}",
    booktitle = "{Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference}",
    publisher = {The MIT Press},
    year = {2007},
    month = {09},
    doi = {10.7551/mitpress/7503.003.0006},
    url = {https://doi.org/10.7551/mitpress/7503.003.0006},
    eprint = {https://direct.mit.edu/book/chapter-pdf/2139612/9780262256919\_caa.pdf},
}
@misc{deepQLearningFromDemo,
      title={Deep Q-learning from Demonstrations}, 
      author={Todd Hester and Matej Vecerik and Olivier Pietquin and Marc Lanctot and Tom Schaul and Bilal Piot and Dan Horgan and John Quan and Andrew Sendonaris and Gabriel Dulac-Arnold and Ian Osband and John Agapiou and Joel Z. Leibo and Audrunas Gruslys},
      year={2017},
      eprint={1704.03732},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}